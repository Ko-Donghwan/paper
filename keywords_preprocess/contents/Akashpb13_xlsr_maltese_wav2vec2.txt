<div class="model-card-content prose md:px-6 md:-mx-6 lg:-mr-20 lg:pr-20 xl:-mr-24 xl:pr-24 2xl:-mr-36 2xl:pr-36 hf-sanitized hf-sanitized-SnwUzyETM2yMxbS8FKVqe">
<!-- HTML_TAG_START --><h1 class="relative group flex items-center">
<a class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" href="#wav2vec2-large-xlsr-53-maltese" id="wav2vec2-large-xlsr-53-maltese" rel="nofollow">
<span class="header-link"><svg aria-hidden="true" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" height="1em" preserveaspectratio="xMidYMid meet" role="img" viewbox="0 0 256 256" width="1em" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
</a>
<span>
		Wav2Vec2-Large-XLSR-53-Maltese
	</span>
</h1>
<p>Fine-tuned <a href="https://huggingface.co/facebook/wav2vec2-large-xlsr-53" rel="nofollow">facebook/wav2vec2-large-xlsr-53</a> in Maltese using the <a href="https://huggingface.co/datasets/common_voice" rel="nofollow">Common Voice</a>
When using this model, make sure that your speech input is sampled at 16kHz.</p>
<h2 class="relative group flex items-center">
<a class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" href="#usage" id="usage" rel="nofollow">
<span class="header-link"><svg aria-hidden="true" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" height="1em" preserveaspectratio="xMidYMid meet" role="img" viewbox="0 0 256 256" width="1em" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
</a>
<span>
		Usage
	</span>
</h2>
<p>The model can be used directly (without a language model) as follows:</p>
<pre><code class="language-python"><span class="hljs-keyword">import</span> torchaudio
<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> (
    Wav2Vec2ForCTC,
    Wav2Vec2Processor,
)
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">import</span> sys

model_name = <span class="hljs-string">"Akashpb13/xlsr_maltese_wav2vec2"</span>
device = <span class="hljs-string">"cuda"</span>
chars_to_ignore_regex = <span class="hljs-string">'[\\,\\?\\.\\!\\-\\;\\:\\"\\“\\%\\‘\\”\\�\\)\\(\\*)]'</span>

model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)
processor = Wav2Vec2Processor.from_pretrained(model_name)

ds = load_dataset(<span class="hljs-string">"common_voice"</span>, <span class="hljs-string">"mt"</span>, split=<span class="hljs-string">"test"</span>, data_dir=<span class="hljs-string">"./cv-corpus-6.1-2020-12-11"</span>)

resampler = torchaudio.transforms.Resample(orig_freq=<span class="hljs-number">48_000</span>, new_freq=<span class="hljs-number">16_000</span>)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">map_to_array</span>(<span class="hljs-params">batch</span>):
    speech, _ = torchaudio.load(batch[<span class="hljs-string">"path"</span>])
    batch[<span class="hljs-string">"speech"</span>] = resampler.forward(speech.squeeze(<span class="hljs-number">0</span>)).numpy()
    batch[<span class="hljs-string">"sampling_rate"</span>] = resampler.new_freq
    batch[<span class="hljs-string">"sentence"</span>] = re.sub(chars_to_ignore_regex, <span class="hljs-string">''</span>, batch[<span class="hljs-string">"sentence"</span>]).lower() + <span class="hljs-string">" "</span>
    <span class="hljs-keyword">return</span> batch

ds = ds.<span class="hljs-built_in">map</span>(map_to_array)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">map_to_pred</span>(<span class="hljs-params">batch</span>):
    features = processor(batch[<span class="hljs-string">"speech"</span>], sampling_rate=batch[<span class="hljs-string">"sampling_rate"</span>][<span class="hljs-number">0</span>], padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">"pt"</span>)
    input_values = features.input_values.to(device)
    attention_mask = features.attention_mask.to(device)
    <span class="hljs-keyword">with</span> torch.no_grad():
        logits = model(input_values, attention_mask=attention_mask).logits
    pred_ids = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)
    batch[<span class="hljs-string">"predicted"</span>] = processor.batch_decode(pred_ids)
    batch[<span class="hljs-string">"target"</span>] = batch[<span class="hljs-string">"sentence"</span>]
    <span class="hljs-keyword">return</span> batch

result = ds.<span class="hljs-built_in">map</span>(map_to_pred, batched=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">1</span>, remove_columns=<span class="hljs-built_in">list</span>(ds.features.keys()))

wer = load_metric(<span class="hljs-string">"wer"</span>)
<span class="hljs-built_in">print</span>(wer.compute(predictions=result[<span class="hljs-string">"predicted"</span>], references=result[<span class="hljs-string">"target"</span>]))
</code></pre>
<p><strong>Test Result</strong>: 29.42 %</p>
<!-- HTML_TAG_END --></div>