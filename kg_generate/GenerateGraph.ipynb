{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import rdflib\n",
    "from rdflib import Graph, RDF, XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f'./models/{model_name}/merged_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom namespace for your data\n",
    "KOAI = rdflib.Namespace(\"http://knowledgemap.kr/koai/def/type/\")\n",
    "\n",
    "# Create a new RDF graph\n",
    "g = rdflib.Graph()\n",
    "\n",
    "# Add namespace prefix to the graph\n",
    "g.bind(\"koai\", KOAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to add a model's information to the RDF graph dynamically\n",
    "def add_model_info_to_graph(model_info):\n",
    "    # Generate model URI based on the model ID\n",
    "    model_uri = KOAI[model_info[\"id\"].replace(\"-\", \"_\").replace(\"/\", \"_\")]\n",
    "    g.add((model_uri, RDF.type, KOAI.AIModel))\n",
    "    \n",
    "    # Loop through each key in the model_info dictionary and add to RDF\n",
    "    for key, value in model_info.items():\n",
    "        if key in ['finetune', 'adapter', 'merge', 'quantized', 'dataset'] or value is None:\n",
    "            continue  # Skip keys that need to be handled separately\n",
    "\n",
    "        if isinstance(value, list):  # If the value is a list, handle it separately\n",
    "            for item in value:\n",
    "                item_uri = KOAI[item.replace(\"-\", \"_\").replace(\"/\", \"_\")] if isinstance(item, str) else rdflib.Literal(item)\n",
    "                g.add((model_uri, KOAI[key], item_uri))\n",
    "        elif isinstance(value, bool):  # If the value is a boolean\n",
    "            g.add((model_uri, KOAI[key], rdflib.Literal(value, datatype=XSD.boolean)))\n",
    "        elif isinstance(value, int):  # If the value is an integer\n",
    "            g.add((model_uri, KOAI[key], rdflib.Literal(value, datatype=XSD.integer)))\n",
    "        elif isinstance(value, str):  # If the value is a string\n",
    "            g.add((model_uri, KOAI[key], rdflib.Literal(value)))\n",
    "        else:  # Default case for other data types\n",
    "            g.add((model_uri, KOAI[key], rdflib.Literal(str(value))))\n",
    "\n",
    "    # Handle finetuned models separately\n",
    "    if model_info.get(\"finetune\"):\n",
    "        for finetuned_model in model_info[\"finetune\"]:\n",
    "            finetuned_model_uri = KOAI[finetuned_model.replace(\"-\", \"_\").replace(\"/\", \"_\")]\n",
    "            g.add((finetuned_model_uri, RDF.type, KOAI.FinetunedModel))\n",
    "            g.add((finetuned_model_uri, KOAI.isFineTunedFrom, model_uri))\n",
    "            g.add((model_uri, KOAI.hasFineTunedModel, finetuned_model_uri))\n",
    "\n",
    "    # Handle adapter models separately\n",
    "    if model_info.get(\"adapter\"):\n",
    "        for adapter_model in model_info[\"adapter\"]:\n",
    "            adapter_model_uri = KOAI[adapter_model.replace(\"-\", \"_\").replace(\"/\", \"_\")]\n",
    "            g.add((adapter_model_uri, RDF.type, KOAI.AdaptedModel))\n",
    "            g.add((adapter_model_uri, KOAI.isAdaptedFrom, model_uri))\n",
    "            g.add((model_uri, KOAI.hasAdapterModel, adapter_model_uri))\n",
    "\n",
    "    # Handle merged models separately\n",
    "    if model_info.get(\"merge\"):\n",
    "        for merge_model in model_info[\"merge\"]:\n",
    "            merge_model_uri = KOAI[merge_model.replace(\"-\", \"_\").replace(\"/\", \"_\")]\n",
    "            g.add((merge_model_uri, RDF.type, KOAI.MergedModel))\n",
    "            g.add((merge_model_uri, KOAI.isMergedFrom, model_uri))\n",
    "            g.add((model_uri, KOAI.hasMergedModel, merge_model_uri))\n",
    "\n",
    "    # Handle quantized models separately\n",
    "    if model_info.get(\"quantized\"):\n",
    "        for quantized_model in model_info[\"quantized\"]:\n",
    "            quantized_model_uri = KOAI[quantized_model.replace(\"-\", \"_\").replace(\"/\", \"_\")]\n",
    "            g.add((quantized_model_uri, RDF.type, KOAI.QuantizedModel))\n",
    "            g.add((quantized_model_uri, KOAI.isQuantizedFrom, model_uri))\n",
    "            g.add((model_uri, KOAI.hasQuantizedModel, quantized_model_uri))\n",
    "\n",
    "    # Handle datasets separately\n",
    "    if model_info.get(\"dataset\"):\n",
    "        for dataset in model_info[\"dataset\"]:\n",
    "            dataset_uri = KOAI[dataset.replace(\"-\", \"_\").replace(\"/\", \"_\")]\n",
    "            g.add((dataset_uri, RDF.type, KOAI.Dataset))\n",
    "            g.add((dataset_uri, KOAI.isUsedBy, model_uri))\n",
    "            g.add((dataset_uri, KOAI.name, rdflib.Literal(dataset)))\n",
    "            g.add((model_uri, KOAI.usesDataset, dataset_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing RDF graph loaded.\n",
      "Updated RDF graph has been saved to model_data.ttl\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path\n",
    "output_file_path = \"model_data.ttl\"\n",
    "\n",
    "# Load the existing RDF graph\n",
    "g = Graph()\n",
    "try:\n",
    "    g.parse(output_file_path, format=\"turtle\")\n",
    "    print(\"Existing RDF graph loaded.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No existing RDF file found. Creating a new one.\")\n",
    "\n",
    "# Add new model information\n",
    "add_model_info_to_graph(data)\n",
    "\n",
    "# Serialize and save the updated RDF graph\n",
    "g.serialize(destination=output_file_path, format=\"turtle\")\n",
    "\n",
    "print(f\"Updated RDF graph has been saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
